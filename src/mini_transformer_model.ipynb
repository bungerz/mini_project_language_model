{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b63f0100",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3fa6a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from my_tokenizer import CharDataset\n",
    "from my_gpt import SmolGPT\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5e0a13",
   "metadata": {},
   "source": [
    "#### Unit testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "568fc8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]9;4;3;\u001b\\\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.3, pytest-9.0.0, pluggy-1.6.0 -- /home/aenh/git/mini_project_language_model/.venv/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/aenh/git/mini_project_language_model/src\n",
      "plugins: anyio-4.11.0\n",
      "collected 6 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "my_tests.py::test_tokenizer_roundtrip \u001b]9;4;1;0\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m                             [ 16%]\u001b[0m\n",
      "my_tests.py::test_single_attention_head \u001b]9;4;1;16\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m                           [ 33%]\u001b[0m\n",
      "my_tests.py::test_multi_attention_head \u001b]9;4;1;33\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m                            [ 50%]\u001b[0m\n",
      "my_tests.py::test_ffn \u001b]9;4;1;50\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m                                             [ 66%]\u001b[0m\n",
      "my_tests.py::test_transformer_block \u001b]9;4;1;66\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m                               [ 83%]\u001b[0m\n",
      "my_tests.py::test_full_model \u001b]9;4;1;83\u001b\\\u001b[32mPASSED\u001b[0m\u001b[32m                                      [100%]\u001b[0m\u001b]9;4;0;\u001b\\\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m6 passed\u001b[0m\u001b[32m in 1.60s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest my_tests.py -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff97b14",
   "metadata": {},
   "source": [
    "#### Get Data using DataSet / DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8be4be49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load Shakespeare data\n",
    "with open('../data/shakespeare.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Split into train/val (90/10)\n",
    "n = int(0.9 * len(text))\n",
    "train_text, val_text = text[:n], text[n:]\n",
    "\n",
    "# Create datasets using your CharDataset\n",
    "train_dataset = CharDataset(train_text, block_size=128)\n",
    "val_dataset = CharDataset(val_text, block_size=128)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f197ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(model, train_loader, val_loader, device, eval_batches=50):\n",
    "    \"\"\"\n",
    "    Estimate loss on train and val sets\n",
    "    Args:\n",
    "        model: GPT model\n",
    "        train_loader: training DataLoader\n",
    "        val_loader: val DataLoader\n",
    "        device: cpu or cuda\n",
    "        eval_batches: nb of batches to average over\n",
    "    Returns:\n",
    "        a Dictionary with 'train' and 'val' losses\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    \n",
    "    for split, loader in [('train', train_loader), ('val', val_loader)]:\n",
    "        losses = []\n",
    "        for i, (x, y) in enumerate(loader):\n",
    "            if i >= eval_batches:\n",
    "                break\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            _, loss = model(x, y)\n",
    "            losses.append(loss.item())\n",
    "        out[split] = sum(losses) / len(losses)\n",
    "    \n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527bb71c",
   "metadata": {},
   "source": [
    "#### Setting hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1c0f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The project was tested with 12 layers, 8 attention heads, and 768 embedding dimensions, on a single GPU.\n",
    "vocab_size=train_dataset.get_vocab_size(),\n",
    "n_embd=768,\n",
    "block_size=128,\n",
    "num_head=8,\n",
    "num_layers=12,\n",
    "dropout=0.1\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0069fcfa",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0e5f51c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, torch.memory_format memory_format = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mSmolGPT\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_embd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_embd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_head\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_head\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropout\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m.to(device)\n\u001b[32m     11\u001b[39m optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n\u001b[32m     13\u001b[39m num_epochs = \u001b[32m10\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/mini_project_language_model/src/my_gpt.py:26\u001b[39m, in \u001b[36mSmolGPT.__init__\u001b[39m\u001b[34m(self, vocab_size, n_embd, block_size, num_head, num_layers, dropout)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mself\u001b[39m.block_size = block_size \n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m#1. Token Embeddings (from vocab_size to n_embd) :\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m#\"we use learned embeddings to convert the input tokens and output tokens to vectors of dimension d_model\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28mself\u001b[39m.token_embeddings = \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_embd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m#2. Position Embeddings (from block_size to n_embd)\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m#\"We also experimented with using learned positional embeddings [9] instead, and found that the two versions produced nearly identical results\"\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# TODO: Replace with \"sine and cosine functions of different frequencies\"\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mself\u001b[39m.position_embeddings = nn.Embedding(block_size, n_embd)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/mini_project_language_model/.venv/lib/python3.12/site-packages/torch/nn/modules/sparse.py:169\u001b[39m, in \u001b[36mEmbedding.__init__\u001b[39m\u001b[34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, _freeze, device, dtype)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;28mself\u001b[39m.scale_grad_by_freq = scale_grad_by_freq\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    168\u001b[39m     \u001b[38;5;28mself\u001b[39m.weight = Parameter(\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m         \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    170\u001b[39m         requires_grad=\u001b[38;5;129;01mnot\u001b[39;00m _freeze,\n\u001b[32m    171\u001b[39m     )\n\u001b[32m    172\u001b[39m     \u001b[38;5;28mself\u001b[39m.reset_parameters()\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mTypeError\u001b[39m: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, torch.memory_format memory_format = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = SmolGPT(\n",
    "    vocab_size=vocab_size,\n",
    "    n_embd=n_embd,\n",
    "    block_size=block_size,\n",
    "    num_head=num_head,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        logits, loss = model(x, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # evaluation after each epoch\n",
    "    losses = estimate_loss(model, train_loader, val_loader, device)\n",
    "    print(f\"Epoch {epoch:2d} | Train: {losses['train']:.4f} | Val: {losses['val']:.4f}\")\n",
    "\n",
    "print(\"Training complete!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcff8b9",
   "metadata": {},
   "source": [
    "#### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af15321",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "dataset = CharDataset(text, block_size=128)\n",
    "max_new_tokens = 100\n",
    "with torch.no_grad():\n",
    "    context = \"O God, O God!\"\n",
    "    tokens = dataset.encode(context)\n",
    "    #not sure about this, wanting to change the tensor shape\n",
    "    idx = tokens.view(1, len(tokens))\n",
    "    y = model.generate(idx, max_new_tokens)\n",
    "    completion = dataset.itos(y)\n",
    "    print(completion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
